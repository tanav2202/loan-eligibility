---
title: "Loan Eligibility Prediction"
author: "Justin, Ali, Tanav, Gurleen"
jupyter: loan-analysis
execute:
  echo: false
  warning: false
editor: source
---



## Sanity Check

```{python}
import warnings
warnings.filterwarnings('ignore')
# from scripts.temp import temp_fun
# temp_fun()
import pandas as pd
import pickle
from IPython.display import Markdown, display
from tabulate import tabulate
```

## Fetch and Read the data

```{python}
# # Just import and run
# from scripts.data_fetch import download_dataset
# import pandas as pd

# # Download
# download_dataset()
```


```{python}
# Load data
df = pd.read_csv('../data/raw/Loan Eligibility Prediction.csv')  # adjust filename if needed
df.head()
```

## Data Validation

```{python}
# from scripts.data_validation import DataValidation

# validator = DataValidation(
#     DATA_PATH="data/Loan Eligibility Prediction.csv",
#     TARGET_COL="Loan_Status"
# )

# validator.validate_dataset()
```

## Exploratory Data Analysis

### Description of data

The loan eligibility dataset contains information on individual loan applicants and the outcomes of their applications. It includes demographic attributes such as gender, marital status, education level, and number of dependents, along with financial features including applicant income, co-applicant income, loan amount, and loan term. The dataset also records credit history and property area, both of which are key indicators of loan risk and eligibility. The target variable indicates whether each loan was approved or denied. Together, these variables provide a structured view of applicant characteristics and financial profiles, enabling analysis of loan approval patterns and the development of predictive models.

### Statement of Problem

The goal of this classification problem is to develop a predictive model that determines whether a loan application will be approved or denied based on applicant characteristics and financial information. Using features such as gender, education level, number of dependents, income, loan amount, credit history, and property area, the objective is to learn patterns that distinguish approved applications from rejected ones. The resulting model should accurately classify new loan applications and provide insight into the factors that most strongly influence approval decisions.


In what follows we provide an exploratory data analysis to better understand the dataset.  
Below are some raw information about the dataset including the feature types and some statistics associated with the fields.

```{python}
df.info()
```

```{python}
df.describe(include='all').T
```

There no missing values in the dataset, but our data processing handles missing values. 

```{python}
pd.DataFrame(df.isna().sum(), columns=['missing_values'])
```

The target which is the `Loan_status` has the following distribution. The sample is somewhat imbalanced, and we will discuss that in our model training and testing.

```{python}
df['Loan_Status'].value_counts()
```

As we saw above the dataset has multiple types of features that we categorize as follows:

```{python}
numerical_features = ['Applicant_Income', 'Coapplicant_Income', 'Loan_Amount', 'Loan_Amount_Term', 'Dependents']
categorical_features = ['Property_Area']
binary_features = ['Credit_History', 'Gender', 'Married', 'Education', 'Self_Employed']
drop_features = ['Customer_ID']
target_name = 'Loan_Status'
```

```{python}
# from scripts.EDA import EDA
# eda = EDA()
```

```{python}
# eda.univariate_feature_distributions(
#     data=df,
#     column_names=numerical_features
# )
```

`Application_Income` and `Coapplication_Income` exibit right skewed distributions as is common with this type of variable. `Loan_Amount` has a distribution closer to *Normal* but still has a heavy right tail. The loan terms are concentrated around 3-year. The number of dependents are also mostly concentraded on $0$. In our analysis we treat the `Dependent` feature as numerical, but it can also be thought of as a categorical feature.  

An examination of the categorical features reveals several notable differences between approved and rejected loan applications. Property area shows distinct variation across classes: applicants from “*Semiurban*” areas have a noticeably higher approval rate, while those from “*Rural*” areas are more likely to be denied. Credit history is the strongest differentiator in the dataset; applicants with a positive credit history overwhelmingly fall into the approved class, whereas those with no credit history are predominantly rejected, confirming its central role in loan eligibility decisions.

Demographic features exhibit more modest effects. Gender shows a slight skew toward higher approval rates for male applicants, although the difference is not substantial. Married applicants tend to receive approvals more often than unmarried ones, suggesting that household structure may influence perceived creditworthiness or financial stability. Educational background also shows variation: graduates have higher approval rates than non-graduates, reflecting a possible association between education level and financial reliability. Finally, individuals who are self-employed experience a lower approval rate compared with salaried applicants, consistent with the higher income variability typically associated with self-employment.

Overall, `Credit_History`, `Property_Area`, and `Married` status appear to be the most influential categorical features in distinguishing between approved and denied applications, while `Gender`, `Education`, and `Self_Employed` provide weaker but still observable patterns.

```{python}
# eda.compare_categorical_features(
#     data=df,
#     categorical_cols=categorical_features+binary_features,
#     target_name=target_name
# )
```

The density plots for the numerical features highlight meaningful differences between approved and rejected loan applications. `Applicant_Income` and `Coapplicant_Income` both exhibit right-skewed distributions, but approved applicants tend to have slightly higher incomes, suggesting that stronger earning capacity improves approval likelihood. `Loan_Amount` shows a similar pattern: approved applications are more concentrated at moderate loan sizes, whereas rejected applications display a flatter, more dispersed distribution, indicating a higher rejection rate for larger or less typical loan amounts. `Loan_Term` is more uniform across both classes, though standard loan terms appear marginally more common among approved applicants. Together, these density comparisons suggest that income and loan amount provide more discriminative power between the two classes, while loan term contributes comparatively less to separation.

```{python}
# eda.density_feature_plots(
#     data=df,
#     numerical_cols=numerical_features,
#     target=target_name,
#     columns=3
# )
```

The boxplots of the numerical features across the two classes confirm the above-mentioned finding in a new light. `Applicant_Income` and `Coapplicant_Income` show wider distributions for approved applications, indicating that applicants with stronger or more stable earnings are more likely to be approved. `Loan_Amount` displays a noticeably fatter right tail for approved cases, though with considerable overlap between the classes. In contrast, `Loan_Term` exhibits similar quartiles across both groups, suggesting that loan duration does not meaningfully differentiate approved from rejected applications. Overall, the boxplots reinforce that income-related features and loan amount contribute more substantially to loan approval outcomes, while loan term plays a limited role.

```{python}
# eda.boxplot_feature_plots(
#     data=df,
#     numerical_cols=numerical_features,
#     target=target_name,
#     columns=3
# )
```

The correlation heat map shows that the numerical features in the dataset mostly exhibit modest relationships with one another, with most correlations falling in the weak to moderate range. `Applicant_Income` and `Coapplicant_Income` show a mild negative association, reflecting that households with higher primary incomes might have lower secondary incomes. `Loan_Amount` is moderately correlated with `Applicant_Income`, indicating that higher-income applicants tend to seek larger loans. `Loan_Term` shows little correlation with any of the income or loan amount variables, suggesting that the duration of a loan is chosen largely independently of an applicant’s income or requested amount. Overall, the heat map indicates that the numerical features do not exhibit strong collinearity, making them suitable for use together in predictive modeling without concerns about severe multicollinearity.

```{python}
# eda.correlation_plot(
#     data=df, 
#     column_names=numerical_features)
```

## Model Training 

```{python}
# from scripts.model_train import *

# # Preprocess
# X_train, X_test, y_train, y_test, features, scaler = preprocess_data(df)

# # Train and save model
# model = train_classifier(X_train, y_train)
```

# Results & Discussion

```{python}
# Classification Report
classification_report = pd.read_csv("../results/tables/classification_report.csv")
classification_report.rename(columns={'Unnamed: 0': 'metric'}, inplace=True)

# Cross-validation results
cross_validation_results = pd.read_csv("../results/tables/cross_validation_results.csv")

test_scores = pd.read_csv("../results/tables/test_scores.csv")

confusion_matrix_csv = pd.read_csv("../results/tables/confusion_matrix.csv")
```

#### Accuracy Score

The accuracy score of the model is `{python} round(test_scores.iloc[0, 0], 2)`. This means that the model correctly predicts loan eligibility `{python} round(test_scores.iloc[0, 0], 2)*100`% of the time.

#### Confusion Matrix

![Confusion Matrix](../results/figures/confusion_matrix.png){#fig-confusion_matrix_png width=100%}

Based on the confusion matrix, we can derive several key performance metrics for our loan eligibility prediction model. The model correctly predicted `{python} confusion_matrix_csv.iloc[0, 1]` loan denials and `{python} confusion_matrix_csv.iloc[1, 2]` loan approvals. The model incorrectly predicted `{python} confusion_matrix_csv.iloc[0, 2]` loan denials as approvals (false positives) and `{python} confusion_matrix_csv.iloc[1, 1]` loan approvals as denials (false negatives). From this, we can see that the model is better at predicting approvals than denials. Depending on the business context, we may prefer to minimize the false negatives to avoid losing out on potential customers who would have been approved for loans. But, we also need to consider the cost of false positives and minimizing the number of bad loans approved. 

#### Classification Report

```{python}
Markdown(classification_report.to_markdown())
```

From the classification report, we can see that the false precision is `{python} round(classification_report.iloc[0, 1], 2)`. Meaning that when the model predicts a loan will be denied, it is correct `{python} round(classification_report.iloc[0, 1], 2) * 100`% of the time. The recall is `{python} round(classification_report.iloc[1, 1], 2)`, meaning that the model correctly identifies `{python} round(classification_report.iloc[1, 1], 2)*100`% of all actual loan denials. The true precision is `{python} round(classification_report.iloc[0, 2], 2)`, meaning that when the model predicts a loan will be approved, it is correct `{python} round(classification_report.iloc[0, 2], 2)*100`% of the time. The recall is `{python} round(classification_report.iloc[1, 2], 2)`, meaning that the model correctly identifies `{python} round(classification_report.iloc[1, 2], 2)*100`% of all actual loan approvals. From the weighted average column, we can see the overall accuracy of the model is `{python} round(classification_report.iloc[0, 3], 2)`, meaning that the model correctly predicts loan eligibility `{python} round(classification_report.iloc[0, 3], 2)*100`% of the time.

#### Precision Recall Curve

![Precision-Recall Curve](../results/figures/precision_recall_curve.png){#fig-precision_recall width=100%}

From the precision-recall curve, we can see that as we increase the recall, the precision remains high. The AP score is `{python} round(cross_validation_results.iloc[3, 1], 2)`. This indicates good performance of the model in identifying loan approvals. 

#### ROC Curve

![ROC Curve](../results/figures/roc_curve.png){#fig-roc width=100%}

We can see from the ROC curve and the AUC score of `{python} round(classification_report.iloc[2, 3], 2)` that the model has good ability to distinguish between approved and denied loan applications. The score suggests that while the model is effective at distinguishing between the two classes, there is still room for improvement for its predictive performance.

# References
