{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Loan Eligibility Prediction - Results\"\n",
        "author: \"Justin, Ali, Tanav, Gurleen\"\n",
        "jupyter: loan-analysis\n",
        "execute:\n",
        "  echo: false\n",
        "  warning: false\n",
        "editor: source\n",
        "---"
      ],
      "id": "123f4672"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Imports\n",
        "\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from IPython.display import Markdown, display\n",
        "from tabulate import tabulate"
      ],
      "id": "aa238c60",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Results & Discussion"
      ],
      "id": "cb5f373e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Classification Report\n",
        "classification_report = pd.read_csv(\"../results/tables/classification_report.csv\")\n",
        "classification_report.rename(columns={'Unnamed: 0': 'metric'}, inplace=True)\n",
        "\n",
        "# Cross-validation results\n",
        "cross_validation_results = pd.read_csv(\"../results/tables/cross_validation_results.csv\")\n",
        "\n",
        "test_scores = pd.read_csv(\"../results/tables/test_scores.csv\")\n",
        "\n",
        "confusion_matrix_csv = pd.read_csv(\"../results/tables/confusion_matrix.csv\")"
      ],
      "id": "87db76e8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Testing\n",
        "\n",
        "## Accuracy Score\n",
        "\n",
        "## Confusion Matrix\n",
        "\n",
        "![Confusion Matrix](../results/figures/confusion_matrix.png){#fig-confusion_matrix_png width=100%}\n",
        "\n",
        "Based on the confusion matrix, we can derive several key performance metrics for our loan eligibility prediction model. The model correctly predicted `{python} confusion_matrix_csv.iloc[0, 1]` loan denials and `{python} confusion_matrix_csv.iloc[1, 2]` loan approvals. The model incorrectly predicted `{python} confusion_matrix_csv.iloc[0, 2]` loan denials as approvals (false positives) and `{python} confusion_matrix_csv.iloc[1, 1]` loan approvals as denials (false negatives). From this, we can see that the model is better at predicting approvals than denials. Depending on the business context, we may prefer to minimize the false negatives to avoid losing out on potential customers who would have been approved for loans. But, we also need to consider the cost of false positives and minimizing the number of bad loans approved. \n",
        "\n",
        "## Classification Report"
      ],
      "id": "58397e28"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Markdown(classification_report.to_markdown())"
      ],
      "id": "c5c64587",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the classification report, we can see that the false precision is `{python} round(classification_report.iloc[0, 1], 2)`. Meaning that when the model predicts a loan will be denied, it is correct `{python} round(classification_report.iloc[0, 1], 2) * 100`% of the time. The recall is 0.47, meaning that the model correctly identifies 47% of all actual loan denials. The true precision is 0.80, meanin gthat when the model predicts a loan will be apporved, it is correct 80% of the time. The recall is 0.95, meaning that the model correctly identifies 95% of all actual loan approvals. From the weighted average column, we can see the overall accuracy of the model is 0.80, meaning that the model correctly predicts loan eligibility 80% of the time.\n",
        "\n",
        "## Precision Recall Curve\n",
        "\n",
        "![Precision-Recall Curve](../results/figures/precision_recall_curve.png){#fig-precision_recall width=100%}\n",
        "\n",
        "From the precision-recall curve, we can see that as we increase the recall, the precision remains high. The AP score is 0.87. This indicates good performance of the model in identifying loan approvals. \n",
        "\n",
        "## ROC Curve\n",
        "\n",
        "![ROC Curve](../results/figures/roc_curve.png){#fig-roc width=100%}\n",
        "\n",
        "We can see from the ROC curve and the AUC score of 0.80 that the model has good ability to distinguish between approved and denied loan applications. The score suggests that while the model is effective at distinguishing between the two classes, there is still room for improvement for its predictive performance.\n",
        "\n",
        "## References"
      ],
      "id": "e248c08f"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "loan-analysis",
      "language": "python",
      "display_name": "Python (loan-analysis)",
      "path": "/Users/justinmak/Library/Jupyter/kernels/loan-analysis"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}