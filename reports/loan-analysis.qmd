---
title: "Loan Eligibility Prediction Analysis"
author: "Tanav Singh Bajaj, Ali Boloor, Gurleen Kaur, Justin Mak"
date: today
format:
  html:
    toc: true
    toc-depth: 3
    toc-title: "Table of Contents"
    number-sections: true
    embed-resources: true
    code-fold: false
    theme: cosmo
  pdf:
    toc: true
    number-sections: true
    colorlinks: true
bibliography: references.bib
execute:
  echo: false
  warning: false
  message: false
  timeout: 300
---

```{python}
# Import required libraries
import pandas as pd
import numpy as np
from IPython.display import Markdown
from tabulate import tabulate
```

# Introduction

Loan approval decisions are critical for financial institutions, impacting both business profitability and customer satisfaction. Traditional manual assessment processes can be time-consuming and subject to inconsistencies. This project develops a machine learning model to predict loan eligibility based on applicant characteristics, enabling faster and more consistent decision-making.

The primary research question addressed in this analysis is:

> **Can we accurately predict loan eligibility based on applicant demographic and financial information?**

This analysis uses logistic regression to build a binary classifier that predicts whether a loan application will be approved or rejected. The model is trained on historical loan application data containing features such as applicant income, credit history, employment status, and property characteristics.

# Data Description

The dataset used in this analysis was sourced from Kaggle [@kaggle_loan_data] and contains information about loan applications. The dataset includes both demographic information (gender, marital status, education) and financial indicators (income, loan amount, credit history).

```{python}
# Load the training data for inline statistics
df_train = pd.read_csv('../data/processed/df_train.csv')
n_samples = len(df_train)
n_features = df_train.shape[1] - 1  # Excluding target variable
n_approved = (df_train['Loan_Status'] == 1).sum()
approval_rate = (n_approved / n_samples * 100)
```

```{python}
#| output: asis
print(f"The training dataset contains {n_samples:,} loan applications with {n_features} predictor variables. Of these applications, {n_approved:,} ({approval_rate:.1f}%) were approved, indicating a moderately imbalanced dataset.")
```

## Key Features

The predictor variables in our dataset include:

- **Demographic Features**: Gender, marital status, number of dependents, education level
- **Financial Features**: Applicant income, co-applicant income, loan amount, loan term
- **Credit Features**: Credit history (binary indicator)
- **Property Features**: Property area (urban, semi-urban, rural)

The target variable is **Loan_Status**, a binary indicator where 1 represents loan approval and 0 represents rejection.

# Exploratory Data Analysis

Before building the predictive model, we conducted exploratory data analysis (EDA) to understand the data distribution, identify potential relationships, and detect any data quality issues.

## Univariate Analysis

@fig-univariate shows the distribution of key numerical features in the dataset. The distributions reveal several important characteristics of the applicant population.

![Distribution of numerical features in the training data](../results/figures/univariate.png){#fig-univariate}

Notable observations include:

- Applicant income shows a right-skewed distribution with most applicants earning between \$2,500 and \$6,000
- Loan amounts are similarly right-skewed, with most loans requested in the \$100,000 to \$200,000 range
- Loan terms are predominantly concentrated at 360 months (30-year mortgages)

## Categorical Variables and Loan Status

@fig-categorical compares loan approval rates across different categorical variables, providing insight into which demographic factors may influence approval decisions.

![Loan approval rates by categorical features](../results/figures/categorical_compare.png){#fig-categorical}

Key findings include:

- Applicants with positive credit history show substantially higher approval rates
- Married applicants appear to have slightly higher approval rates than unmarried applicants
- Property area shows minimal variation in approval rates across urban, semi-urban, and rural categories

## Feature Distributions by Loan Status

@fig-density presents density plots comparing the distribution of numerical features between approved and rejected applications.

![Density distributions of numerical features by loan approval status](../results/figures/density_plots.png){#fig-density}

The density plots reveal:

- Approved loans tend to have applicants with slightly higher incomes
- The loan amount distributions are relatively similar between approved and rejected applications
- Co-applicant income shows notable differences, with approved applications having higher co-applicant income on average

## Outlier Detection

@fig-boxplots displays boxplots for numerical features grouped by loan status, helping identify potential outliers and distributional differences.

![Boxplots showing outliers in numerical features by loan status](../results/figures/boxplots.png){#fig-boxplots}

The boxplot analysis indicates:

- Several outliers exist in both applicant and co-applicant income
- Loan amount contains some extreme values that may represent luxury properties or commercial loans
- Most features show relatively symmetric distributions around their medians

## Feature Correlations

@fig-correlation displays the correlation matrix between numerical features, helping identify multicollinearity concerns.

![Correlation heatmap of numerical features](../results/figures/correlation_heatmap.png){#fig-correlation}

The correlation analysis shows:

- Moderate positive correlation between applicant income and loan amount (0.57)
- Weak correlation between most other feature pairs, suggesting limited multicollinearity issues
- Credit history shows weak correlation with numerical features, indicating it provides independent information

# Methods

## Data Preprocessing

The raw data underwent several preprocessing steps to prepare it for modeling:

1. **Missing Value Imputation**: Missing values in numerical features were imputed using median values, while categorical features used mode imputation
2. **Feature Encoding**: Categorical variables were encoded using one-hot encoding to create binary indicator variables
3. **Feature Scaling**: Numerical features were standardized using StandardScaler to have zero mean and unit variance
4. **Train-Test Split**: The data was split into 80% training and 20% test sets using stratified sampling to maintain class balance

All preprocessing was performed using scikit-learn [@sklearn] pipelines to ensure reproducibility and prevent data leakage.

## Model Selection

We chose logistic regression as our primary model for several reasons:

- **Interpretability**: Logistic regression coefficients can be interpreted as log-odds ratios, providing clear insights into feature importance
- **Efficiency**: The model trains quickly and makes fast predictions, suitable for production deployment
- **Baseline Performance**: Logistic regression serves as a strong baseline for binary classification tasks
- **Probabilistic Output**: The model provides probability estimates, useful for risk assessment and decision thresholds

The logistic regression model was trained with a maximum of 1000 iterations to ensure convergence, using the Limited-memory BFGS (L-BFGS) optimization algorithm.

## Model Evaluation

We evaluated the model using multiple metrics to assess different aspects of performance:

```{python}
# Load evaluation results
test_scores = pd.read_csv('../results/tables/test_scores.csv')
cv_results = pd.read_csv('../results/tables/cross_validation_results.csv', index_col=0)
confusion_matrix = pd.read_csv('../results/tables/confusion_matrix.csv', index_col=0)
classification_report = pd.read_csv('../results/tables/classification_report.csv', index_col=0)

# Extract key metrics
test_accuracy = test_scores['accuracy'].values[0]
test_f2 = test_scores['F2 score (beta = 2)'].values[0]
cv_accuracy_mean = cv_results.loc['accuracy', 'mean']
cv_accuracy_std = cv_results.loc['accuracy', 'std']
```

- **Accuracy**: Overall correctness of predictions
- **Precision**: Of loans predicted as approved, what proportion were truly approved
- **Recall**: Of truly approved loans, what proportion were correctly identified
- **F2 Score**: Weighted harmonic mean of precision and recall (Î²=2 emphasizes recall)
- **ROC-AUC**: Area under the receiver operating characteristic curve

We used 10-fold cross-validation on the training set to assess model stability and prevent overfitting.

# Results

## Model Performance

### Cross-Validation Results

@tbl-cv-results shows the cross-validation performance across 10 folds on the training data.

```{python}
#| label: tbl-cv-results
#| tbl-cap: "10-fold cross-validation results on training data"

cv_display = cv_results.copy()
cv_display['mean'] = cv_display['mean'].apply(lambda x: f"{x:.4f}")
cv_display['std'] = cv_display['std'].apply(lambda x: f"{x:.4f}")
Markdown(cv_display.to_markdown())
```

```{python}
#| output: asis
print(f"The model achieves a mean cross-validation accuracy of {cv_accuracy_mean:.2%} with a standard deviation of {cv_accuracy_std:.2%}, indicating consistent performance across folds.")
```

### Test Set Performance

```{python}
#| output: asis
print(f"The model was evaluated on the held-out test set to assess generalization performance. The test set accuracy is {test_accuracy:.2%} and the F2 score is {test_f2:.4f}.")
```

@tbl-confusion-matrix presents the confusion matrix on the test set.

```{python}
#| label: tbl-confusion-matrix
#| tbl-cap: "Confusion matrix on test data"

Markdown(confusion_matrix.to_markdown())
```

@tbl-classification-report provides detailed precision, recall, and F1 scores for each class.

```{python}
#| label: tbl-classification-report
#| tbl-cap: "Classification report on test data"

# Format the classification report for better display
report_display = classification_report.round(4)
Markdown(report_display.to_markdown())
```

## ROC and Precision-Recall Curves

@fig-roc shows the Receiver Operating Characteristic (ROC) curve, which illustrates the trade-off between true positive rate and false positive rate at various classification thresholds.

![ROC curve showing model discrimination ability](../results/figures/roc_curve.png){#fig-roc}

@fig-pr shows the Precision-Recall curve, which is particularly useful for imbalanced datasets as it focuses on the positive class performance.

![Precision-Recall curve for loan approval predictions](../results/figures/precision_recall_curve.png){#fig-pr}

The high area under both curves indicates strong discriminative ability of the model.

# Discussion

## Key Findings

Our analysis reveals several important insights about loan eligibility prediction:

1. **Credit history dominates**: The presence of positive credit history is the strongest predictor of loan approval, consistent with traditional lending practices
2. **Income matters**: Both applicant and co-applicant income show positive associations with loan approval
3. **Model performance**: The logistic regression model achieves strong predictive performance with test accuracy exceeding 80%
4. **Interpretability**: The model's simplicity allows stakeholders to understand which factors drive approval decisions

## Limitations

Several limitations should be considered when interpreting these results:

- **Data quality**: The dataset contains missing values that were imputed, which may introduce bias
- **Feature engineering**: Limited feature engineering was performed; interaction terms and polynomial features might improve performance
- **Model complexity**: We used only logistic regression; more complex models (e.g., random forests, gradient boosting) might achieve better performance
- **Temporal validity**: The dataset is static and may not reflect current lending practices or economic conditions

## Future Work

Future improvements to this analysis could include:

1. **Advanced models**: Experiment with ensemble methods and neural networks
2. **Feature engineering**: Create interaction terms and domain-specific features
3. **Fairness analysis**: Assess model fairness across demographic groups to prevent discriminatory lending
4. **Deployment considerations**: Develop an API for real-time predictions and model monitoring

# Conclusion

This project successfully developed a logistic regression model for predicting loan eligibility based on applicant characteristics. The model demonstrates strong performance on held-out test data and provides interpretable insights into factors driving loan approval decisions.

The analysis followed reproducible data science best practices, including:

- Modular code organization with separate scripts for each analysis step
- Automated pipeline execution using Make
- Version control with Git and GitHub
- Containerized environment with Docker
- Professional reporting with Quarto

These practices ensure that the analysis can be easily reproduced, audited, and extended by other researchers or practitioners.

# References

::: {#refs}
:::

# Appendix {.appendix}

## Reproducibility

All code and data for this analysis are available at: https://github.com/tanav2202/loan-eligibility

To reproduce this analysis:

```bash
# Clone the repository
git clone git@github.com:tanav2202/loan-eligibility.git
cd loan-eligibility
docker-compose build
docker-compose up -d
docker exec -it loan-analysis bash
make all
```

## Software Versions

- Python: 3.11
- pandas: 2.2.*
- scikit-learn: 1.5.*
- numpy: 2.4.*
- matplotlib: 3.8.*
- Quarto: 1.8.*
